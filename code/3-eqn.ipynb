{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;66;03m# equation solver\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniforge3\\envs\\fio_fieldwork\\Lib\\site-packages\\numpy\\__init__.py:152\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fft\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m polynomial\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ctypeslib\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ma\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniforge3\\envs\\fio_fieldwork\\Lib\\site-packages\\numpy\\random\\__init__.py:180\u001b[0m\n\u001b[0;32m    126\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    177\u001b[0m ]\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pickle\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _common\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _bounded_integers\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniforge3\\envs\\fio_fieldwork\\Lib\\site-packages\\numpy\\random\\_pickle.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmtrand\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomState\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_philox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Philox\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pcg64\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCG64, PCG64DXSM\n",
      "File \u001b[1;32mmtrand.pyx:1\u001b[0m, in \u001b[0;36minit numpy.random.mtrand\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy # equation solver\n",
    "from scipy.optimize import optimize # minimizing\n",
    "# import statsmodels.api as sm # qqplot\n",
    "import h5py # lese matlab data\n",
    "# h5py-3.11.0\n",
    "%matplotlib inline\n",
    "#\n",
    "# quantile-quantile plot\n",
    "# import statsmodels.api as sm\n",
    "#sm.qqplot_2samples(x, y, line='45')\n",
    "#plt.title('Q-Q plot of x and y')\n",
    "#plt.xlabel('Quantiles of x')\n",
    "#plt.ylabel('Quantiles of y')\n",
    "#plt.grid(True)\n",
    "#plt.show()\n",
    "\n",
    "# Constants, from Jenkins\n",
    "rho_i=916\n",
    "L_i=334000\n",
    "rho_ic_i_k_i=2.1\n",
    "rho_w=1030\n",
    "c_w=3974\n",
    "c_i=2108 # from internet, not in Jenkins tables\n",
    "\n",
    "gamma_1=-0.0573\n",
    "gamma_2=0.0832\n",
    "gamma_3=-7.53*10**-4\n",
    "\n",
    "# Elins' values\n",
    "# CdTt=0.0011 # Thermal Stanton\n",
    "# CdTs=3.1*10**-5 # Diffusion Stanton number\n",
    "# CdTts=5.9*10**-4 # Stanton number - not used?\n",
    "\n",
    "#CdTt=0.02*0.0011 # Thermal Stanton\n",
    "#CdTs=0.15*3.1*10**-5 # Diffusion Stanton number\n",
    "\n",
    "# best fit so far\n",
    "# CdTt=0.15*0.0011 # Thermal Stanton\n",
    "# CdTs=0.2*3.1*10**-5 # Diffusion Stanton number\n",
    "# r2 = 0.65 for Pb O 400\n",
    "\n",
    "CdTt=0.15*0.0011 # Thermal Stanton\n",
    "CdTs=0.3*3.1*10**-5 # Diffusion Stanton number\n",
    "\n",
    "CdTts=5.9*10**-4 # Stanton number - not used?\n",
    "Cd=0.0097 # not used\n",
    "Tt=0.011 # not used\n",
    "Ts=3.1*10**-4 # not used\n",
    "Tts=0.006 #  not used\n",
    "\n",
    "# Fixed values\n",
    "T_i=-20\n",
    "S_w=34.4\n",
    "Pb=360\n",
    "\n",
    "\n",
    "# Constants, Elin\n",
    "A=rho_i*L_i\n",
    "B=rho_i*c_i*T_i #\n",
    "C=rho_i*c_i  # \n",
    "D=rho_w*c_w*CdTt\n",
    "E=rho_w*CdTs\n",
    "F=gamma_2+gamma_3*Pb\n",
    "\n",
    "# a is melt/second! multiply by numbers of seconds per year to get m/yr\n",
    "N=365*24*3600\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "for U in np.linspace(0,0.12,5):\n",
    "    TT=np.linspace(-1.95,-1,25)\n",
    "    aa=[]\n",
    "    for i,T in enumerate(TT):\n",
    "        a = sympy.Symbol('a')\n",
    "        f1=(B-A)*a-C*a*(gamma_1*S_w*E/(E+rho_i*a)+F)-D*U*(gamma_1*S_w*E/(E+rho_i*a)+F)+D*U*T\n",
    "        aa.append(N*sympy.nsolve(f1,a,1/N))\n",
    "    ax.plot(TT,aa,label='U='+str(U)+'m/s')\n",
    "ax.legend()\n",
    "ax.grid()   \n",
    "ax.set_ylabel('Melt rate [m/yr]')\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "for T in [-1.9,-1.7,-1.5]:\n",
    "    UU=np.linspace(0.01,0.12,12)\n",
    "    aa=[]\n",
    "    for i,U in enumerate(UU):\n",
    "        a = sympy.Symbol('a')\n",
    "        f1=(B-A)*a-C*a*(gamma_1*S_w*E/(E+rho_i*a)+F)-D*U*(gamma_1*S_w*E/(E+rho_i*a)+F)+D*U*T\n",
    "        aa.append(N*sympy.nsolve(f1,a,1/N))\n",
    "    ax.plot(UU,aa,label='T='+str(T)+'C')\n",
    "ax.legend()\n",
    "ax.grid()   \n",
    "ax.set_ylabel('Melt rate [m/yr]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U=0.1\n",
    "T=-1.9\n",
    "a = sympy.Symbol('a')\n",
    "f1=(B-A)*a-C*a*(gamma_1*S_w*E/(E+rho_i*a)+F)-D*U*(gamma_1*S_w*E/(E+rho_i*a)+F)+D*U*T\n",
    "a = sympy.nsolve(f1,a,1/N)\n",
    "\n",
    "S_b=S_w*E/(E+rho_i*a)\n",
    "T_b=gamma_1*S_b+F\n",
    "\n",
    "check=-A*a+B*a-C*T_b*a-D*U*(T_b-T)\n",
    "print(check) # Should be very close to zero\n",
    "print('S_b='+str(S_b))\n",
    "print('T_b='+str(T_b))\n",
    "print('Meltrate='+str(a*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=rho_i*(B-A-C*F)\n",
    "bb=E*(B-A)-C*gamma_1*S_w*E-C*F*E-D*U*F*rho_i+D*U*T*rho_i\n",
    "cc=D*U*T*E-D*U*F*E-D*U*gamma_1*S_w*E\n",
    "\n",
    "a=(-bb-np.sqrt(bb**2-4*aa*cc))/(2*aa) # meltrate [m/s]\n",
    "print(str(a*N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to implement minimization of RMS of observed melt and parameterized  melt based from 3-eqn solver following this recepie: https://datascience.stackexchange.com/questions/69092/how-to-minimize-mean-square-error-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read obs data\n",
    "f = h5py.File('M2_series.mat','r')\n",
    "print(f.keys())\n",
    "\n",
    "num = np.array(f.get('num'))\n",
    "dh = np.array(f.get('dh'))\n",
    "vsr = np.array(f.get('vsr'))\n",
    "vsr_lin = np.array(f.get('vsr_lin'))\n",
    "t2 = np.array(f.get('t2'))\n",
    "spd2 = np.array(f.get('spd2'))\n",
    "\n",
    "# tr2 = np.array(f.get('t2'))\n",
    "spdf2 = np.array(f.get('spdf2'))\n",
    "\n",
    "# mm = -(dh-np.mean(vsr,axis=0))\n",
    "mm = -(dh-np.mean(vsr,axis=0))-0.45 # offset of staek strain\n",
    "# mm = -(dh-vsr_lin)-0.45 # offset of staek strain\n",
    "t = t2.T\n",
    "spd = spd2.T\n",
    "spd_ = spdf2.T\n",
    "\n",
    "print('langley dh = ')\n",
    "print(str(-(0.9+0.84)))\n",
    "\n",
    "print('ApRES dh = ')\n",
    "print(str(np.nanmean(dh)))\n",
    "\n",
    "print('stake strain = ')\n",
    "print(str(0.9))\n",
    "print('ApRES strain = ')\n",
    "print(str(np.mean(vsr,axis=0)))\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(num, mm)\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(num, t)\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(num, spd)\n",
    "ax.plot(num, spd_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find non-neagtive values\n",
    "ii = np.isfinite(spd * t * mm) # & (spd>0.05)\n",
    "\n",
    "UU = spd[ii] # + 0.07 fits magntude, but worsens r2\n",
    "TT = t[ii] # + 0.15\n",
    "mm_obs = mm[ii]\n",
    "\n",
    "\n",
    "#rnd = np.random.rand(100)\n",
    "#rndi = np.round(rnd*len(UU))\n",
    "\n",
    "#UU = UU[rndi.astype('int64')]\n",
    "#TT = TT[rndi.astype('int64')]\n",
    "#mm_obs = mm_obs[rndi.astype('int64')]\n",
    "\n",
    "#print(str(mm_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocity and temperature series\n",
    "#UU = np.linspace(0,0.12,25)\n",
    "#TT = np.linspace(-1.95,-1,25)\n",
    "## melt rate series\n",
    "#melt_obs = UU*TT\n",
    "\n",
    "# find non-neagtive values\n",
    "# ii = np.isfinite(spd * t * mm)\n",
    "# UU = spd[ii] # + 0.07 fits magntude, but worsens r2\n",
    "# TT = t[ii] # + 0.15\n",
    "# mm_obs = mm[ii]\n",
    "\n",
    "# Fixed values\n",
    "T_i=0 #-20\n",
    "S_w=34.4\n",
    "Pb=360\n",
    "\n",
    "def melt_para(ftt,fts,toff,uoff):\n",
    "    aa=[]\n",
    "    # CdTt=0.15*0.0011 # Thermal Stanton\n",
    "    # CdTs=0.2*3.1*10**-5 # Diffusion Stanton number\n",
    "    CdTt=ftt*0.0011 # Thermal Stanton\n",
    "    # CdTs=fts*3.1*10**-5 # Diffusion Stanton number\n",
    "    CdTs=CdTt/30\n",
    "\n",
    "    # Constants, Elin\n",
    "    A=rho_i*L_i\n",
    "    B=rho_i*c_i*T_i #\n",
    "    C=rho_i*c_i  # \n",
    "    D=rho_w*c_w*CdTt\n",
    "    E=rho_w*CdTs\n",
    "    F=gamma_2+gamma_3*Pb\n",
    "\n",
    "    T = TT + toff\n",
    "    U = UU + uoff\n",
    "    aa=rho_i*(B-A-C*F)\n",
    "    bb=E*(B-A)-C*gamma_1*S_w*E-C*F*E-D*U*F*rho_i+D*U*T*rho_i\n",
    "    cc=D*U*T*E-D*U*F*E-D*U*gamma_1*S_w*E\n",
    "    aa=N*(-bb-np.sqrt(bb**2-4*aa*cc))/(2*aa) # meltrate [m/yr]\n",
    "    # add convective part\n",
    "    # aa[U<0.02] = aa[U<0.02] +1.93*np.abs(T[U<0.02]+2.15)**(4/3)\n",
    "    # aa[U<0.02] = aa[U<0.02] +2.5*np.abs(T[U<0.02]+2.15)**(4/3)\n",
    "    # aa = aa +5.5*np.abs(T+2.15)**(4/3)\n",
    "    # aa = aa +2*np.abs(T+2.15)**(4/3)\n",
    "    aa = aa +fts*np.abs(T+2.15)**(4/3)\n",
    "    \n",
    "    #for i,element in enumerate(TT):\n",
    "    #    T = TT[i] + toff\n",
    "    #    U = UU[i] + uoff\n",
    "    #    #a = 5 +5\n",
    "    #    # a = T_i +5\n",
    "    #    a = sympy.Symbol('a')\n",
    "    #    f1=(B-A)*a-C*a*(gamma_1*S_w*E/(E+rho_i*a)+F)-D*U*(gamma_1*S_w*E/(E+rho_i*a)+F)+D*U*T\n",
    "    #    aa.append(N*sympy.nsolve(f1,a,1/N))\n",
    "    return aa\n",
    "\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_score_man(y_obs, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the coefficient of determination (R^2) between the observed data and the predicted data.\n",
    "\n",
    "    Parameters:\n",
    "    y_obs (numpy array): The observed data.\n",
    "    y_pred (numpy array): The predicted data.\n",
    "\n",
    "    Returns:\n",
    "    float: The R^2 value.\n",
    "    \"\"\"\n",
    "    # Calculate the residuals (differences between observed and predicted data)\n",
    "    resid = y_pred - y_obs\n",
    "    \n",
    "    # Calculate the sum of squares of residuals\n",
    "    SSresid = np.sum(resid ** 2)\n",
    "    \n",
    "    # Calculate the total sum of squares (variance of the observed data times the number of observations minus one)\n",
    "    # Note: np.var with ddof=1 calculates the sample variance\n",
    "    SStotal = (len(y_obs) - 1) * np.var(y_obs, ddof=1)\n",
    "    \n",
    "    # Calculate the R^2 value\n",
    "    r2_val = 1 - SSresid / SStotal\n",
    "    \n",
    "    return r2_val\n",
    "\n",
    "# Example usage\n",
    "# ys = np.array([...])  # Observed data\n",
    "# y1s = np.array([...]) # Predicted data\n",
    "# r_squared = calculate_r_squared(ys, y1s)\n",
    "# print(r_squared)\n",
    "\n",
    "# mm_par = melt_para(ftt,fts,toff,soff)\n",
    "# mm_par = melt_para(0.15,0.2,0,0)\n",
    "\n",
    "# first extension with so far best fit\n",
    "#ftt = np.arange(0.01, 0.1, 0.005) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#fts = np.array([0.005, 0.007, 0.01, 0.013, 0.015, 0.4, 0.5, 0.6]) # np.arange(0.01, 1.2, 0.01) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#toffs = np.arange(-0.15, 0.15, 0.01) \n",
    "#uoffs = np.arange(-0.02, 0.08, 0.01) # np.arange(-0.1, 0.1, 0.01) \n",
    "\n",
    "\n",
    "\n",
    "ftt = np.arange(0.01, 0.1, 0.005) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "fts = np.array([0.005, 0.007, 0.01, 0.013, 0.015, 0.4, 0.5, 0.6, 1.5]) # np.arange(0.01, 1.2, 0.01) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "toffs = np.arange(-0.15, 0.15, 0.01) \n",
    "uoffs = np.arange(-0.02, 0.08, 0.01) # np.arange(-0.1, 0.1, 0.01) \n",
    "\n",
    "# large fts values\n",
    "#ftt = np.arange(0.01, 0.2, 0.005) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#fts = np.array([0.01, 0.1, 1, 1.5, 10, 10^5, 10**6, 5*10**7, 10**8, 5*10**8, 10**10, 10**15]) # np.arange(0.01, 1.2, 0.01) # np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#toffs = np.arange(-0.16, 0.16, 0.02) \n",
    "#offs = np.arange(-0.02, 0.08, 0.01) # np.arange(-0.1, 0.1, 0.01) \n",
    "\n",
    "# original small set with good fit for offset, explore large fts gives best fit with square of filtered velocities\n",
    "ftt = np.array([0.09, 0.15, 1, 1.5, 15, 150]) # np.arange(0.05, 0.15, 0.01)\n",
    "fts = np.array([0.2, 0.25, 0.3, 0.35, 1, 10**9, 5*10**9, 10**10, 5*10**10, 10**11])\n",
    "toffs = np.arange(-0.05, 0.15, 0.01) \n",
    "uoffs = np.arange(-0.05, 0.1, 0.01) \n",
    "\n",
    "\n",
    "# explor optiosn to add convective mixing\n",
    "#ftt = np.array([1, 2, 10])\n",
    "ftt = np.arange(0.01, 0.15, 0.02) # np.array([0.01, 0.05, 0.09, 0.15, 0.2, 0.5, 0.7, 1, 1.5]) # np.arange(0.05, 0.15, 0.01)\n",
    "# ftt = np.arange(0.1, 1.5, 0.1)\n",
    "#fts = np.array([0.2, 0.25, 0.3, 0.35, 1, 10**9, 5*10**9, 10**10, 5*10**10, 10**11])\n",
    "#fts = np.array([0.1, 0.5, 1, 10])\n",
    "#fts = np.array([1])\n",
    "#fts = np.arange(20, 40, 2) # np.array([25, 30, 35, 50])\n",
    "fts = np.array([0, 2, 4])\n",
    "toffs = np.arange(-0.05, 0.15, 0.01) \n",
    "uoffs = np.arange(-0.05, 0.1, 0.01) \n",
    "\n",
    "\n",
    "# original small set with good fit for offset\n",
    "#ftt = np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#fts = np.array([0.01, 0.05, 0.15, 0.2, 0.5, 1, 1.5])\n",
    "#toffs = np.arange(-0.15, 0.15, 0.01) \n",
    "#uoffs = np.arange(-0.1, 0.1, 0.01) \n",
    "\n",
    "print('initialize arrays')\n",
    "\n",
    "mm_pars = np.zeros((len(ftt), len(fts), len(toffs), len(uoffs), len(ii)))*np.nan\n",
    "mm_r2s_off = np.zeros((len(ftt), len(fts), len(toffs), len(uoffs)))\n",
    "mm_r2s_abs = np.zeros((len(ftt), len(fts), len(toffs), len(uoffs)))\n",
    "\n",
    "print('start loop')\n",
    "\n",
    "for i in range(ftt.size):\n",
    "    #print(str(i))\n",
    "    for j in range(fts.size):\n",
    "        for k in range(toffs.size):\n",
    "            for l in range(uoffs.size):\n",
    "                dum = np.array(melt_para(ftt[i],fts[j],toffs[k],uoffs[l]))\n",
    "                \n",
    "                mm_pars[i, j, k, l, np.squeeze(ii)] = dum\n",
    "                mm_r2s_off[i, j, k, l] = r2_score_man(mm_obs-np.mean(mm_obs), dum-np.mean(dum))\n",
    "                mm_r2s_abs[i, j, k, l] = r2_score_man(mm_obs, dum)\n",
    "    sys.stdout.write('.')\n",
    "                #print(str(i))\n",
    "                #print(str(j))\n",
    "                #print(str(k))\n",
    "                #print(str(l))    \n",
    "    \n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mm_r2s\n",
    "im_aoff = np.where(mm_r2s_off==np.nanmax(mm_r2s_off[:,:,:,:])) # force toff=0, uoff=0, allow free abs offset\n",
    "im_off = np.where(mm_r2s_off==np.nanmax(mm_r2s_off[:,1,5,5])) # force toff=0, uoff=0, allow free abs offset\n",
    "#im_off = np.where(mm_r2s_off==np.nanmax(mm_r2s_off)) # allow free uoff\n",
    "im_abs = np.where(mm_r2s_abs==np.nanmax(mm_r2s_abs[:,:,:,:])) # allow free T & U\n",
    "# im_abs = np.where(mm_r2s_off==np.nanmax(mm_r2s_off[:,:,5,:])) # force toff=0\n",
    "\n",
    "print(str(np.nanmax(mm_r2s_off)))\n",
    "print(im_aoff)\n",
    "print(str(np.nanmax(mm_r2s_off[im_off])))\n",
    "print(im_off)\n",
    "print(str(np.nanmax(mm_r2s_abs[im_abs])))\n",
    "print(im_abs)\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print(ftt[im_aoff[0]])\n",
    "print(ftt[im_off[0]])\n",
    "print(ftt[im_abs[0]])\n",
    "print('')\n",
    "print(fts[im_aoff[1]])\n",
    "print(fts[im_off[1]])\n",
    "print(fts[im_abs[1]])\n",
    "print('')\n",
    "print(toffs[im_aoff[2]])\n",
    "print(toffs[im_off[2]])\n",
    "print(toffs[im_abs[2]])\n",
    "print('')\n",
    "print(uoffs[im_aoff[3]])\n",
    "print(uoffs[im_off[3]])\n",
    "print(uoffs[im_abs[3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original melt rates, manual optimization\n",
    "\n",
    "0.708350356043953\n",
    "(array([1], dtype=int64), array([9], dtype=int64), array([5], dtype=int64), array([7], dtype=int64))\n",
    "0.702708877358194\n",
    "(array([0], dtype=int64), array([3], dtype=int64), array([17], dtype=int64), array([12], dtype=int64))\n",
    "\n",
    "[0.15]\n",
    "[0.09]\n",
    "\n",
    "[1.e+11]\n",
    "[0.35]\n",
    "\n",
    "[6.9388939e-18]\n",
    "[0.12]\n",
    "\n",
    "[0.02]\n",
    "[0.07]\n",
    "\n",
    "0.5 m/yr offset on melt rates\n",
    "\n",
    "0.708350356043953\n",
    "(array([1], dtype=int64), array([9], dtype=int64), array([5], dtype=int64), array([7], dtype=int64))\n",
    "0.7070218038073472\n",
    "(array([1], dtype=int64), array([4], dtype=int64), array([6], dtype=int64), array([7], dtype=int64))\n",
    "\n",
    "[0.15]\n",
    "[0.15]\n",
    "\n",
    "[1.e+11]\n",
    "[1.]\n",
    "\n",
    "[6.9388939e-18]\n",
    "[0.01]\n",
    "\n",
    "[0.02]\n",
    "[0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 1 6 3\n",
    "#mmp=mm_pars[16,7,27,8,:]\n",
    "# mmp=mm_pars[12,5,28,9,:]\n",
    "# mmp = mm_pars[im_off].T\n",
    "mmp = mm_pars[im_off[0], im_abs[1], im_off[2], im_off[3]].T\n",
    "mmpa = mm_pars[im_aoff[0], im_aoff[1],im_aoff[2], im_aoff[3]].T\n",
    "\n",
    "mmp1 = mmp-(np.nanmean(mmp)-np.nanmean(mm))\n",
    "mmp10 = mmpa-(np.nanmean(mmpa)-np.nanmean(mm))\n",
    "# mmp1=mm_pars[2,1,5,7,:]\n",
    "# mmp2=mm_pars[15,7,28,9,:]\n",
    "mmp2 = mm_pars[im_abs[0], im_abs[1], im_abs[2], im_abs[3]].T\n",
    "\n",
    "print('')\n",
    "print(str(np.nanmean(mmp)-np.nanmean(mm)))\n",
    "print(str(np.nanmean(mmpa)-np.nanmean(mm)))\n",
    "\n",
    "fig,ax=plt.subplots(2)\n",
    "# is more concise than this:\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# fig.figure(figsize=(10,6))\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(12)\n",
    "\n",
    "ax[0].plot(num, mm)\n",
    "ax[0].plot(np.squeeze(num), np.squeeze(mmp1))\n",
    "#ax[0].plot(np.squeeze(num), np.squeeze(mmp10))\n",
    "#ax.plot(np.squeeze(num), np.mean(mmp[np.squeeze(ii)]))\n",
    "ax[0].set_title('melt offset corrected')\n",
    "\n",
    "ax[1].plot(num, mm)\n",
    "ax[1].plot(np.squeeze(num), np.squeeze(mmp2))\n",
    "ax[1].set_title('Temperature and velocity offset corrected')\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(\"mygraph.png\")\n",
    "\n",
    "#print(str(np.corrcoef(mm[ii],mmp[np.squeeze(ii)])))\n",
    "\n",
    "#print(str(r2_score_man(mm[ii]-np.mean(mm[ii]),mmp[np.squeeze(ii)]-np.mean(mmp[np.squeeze(ii)]))))\n",
    "\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "fig,ax=plt.subplots(1,2)\n",
    "fig.set_figwidth(10)\n",
    "ax[0].plot(mmp, mm,'.')\n",
    "ax[0].plot([0, 4],[0, 4])\n",
    "\n",
    "ax[1].plot(mmp2, mm,'.')\n",
    "ax[1].plot([0, 4],[0, 4])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(3,2)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "ax[0,0].plot(spd*(2.15+t), mmp1,'.')\n",
    "ax[0,1].plot(spd*(2.15+t), mmp2,'.')\n",
    "ax[1,0].plot(np.sqrt(spd)*(2.15+t), mmp1,'.')\n",
    "ax[1,1].plot(np.sqrt(spd)*(2.15+t), mmp2,'.')\n",
    "ax[2,0].plot((spd)*(2.15+t)*(2.15+t), mmp1,'.')\n",
    "ax[2,1].plot((spd)*(2.15+t)*(2.15+t), mmp2,'.')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "ii = np.isfinite(mm * mmp1 * mmp2)\n",
    "\n",
    "qts = np.arange(0.001, 0.999, 0.001) \n",
    "qmm = np.quantile(mm[ii],qts)\n",
    "qmmp1 = np.quantile(mmp1[ii],qts)\n",
    "qmmp2 = np.quantile(mmp2[ii],qts)\n",
    "\n",
    "\n",
    "ax[0].plot(qmmp1, qmm,'.')\n",
    "ax[0].plot([0, 4], [0, 4])\n",
    "\n",
    "ax[1].plot(qmmp2, qmm,'.')\n",
    "ax[1].plot([0, 4], [0, 4])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = np.zeros(np.shape(dum))\n",
    "print(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize # minimizing\n",
    "\n",
    "def f(params):\n",
    "    dum = np.array(melt_para(params[0],params[1],params[2],params[3]))\n",
    "    if np.isnan(dum.any()):\n",
    "        print('nan encountered')\n",
    "        dum = np.zeros(np.shape(dum))\n",
    "    return 1-r2_score_man(mm_obs, dum)\n",
    "\n",
    "opti_arr = [ftt[im_abs[0]], fts[im_abs[1]], toffs[im_abs[2]], uoffs[im_abs[3]]]\n",
    "#opti_arr = [ftt[im_abs[0]], fts[im_abs[1]], [0], [0]]\n",
    "opti = np.squeeze(np.array(opti_arr).T)\n",
    "print(opti)\n",
    "r2 = f(opti)\n",
    "print(r2)\n",
    "print(mm_r2s_abs[im_abs])\n",
    "\n",
    "initial_guess = opti #[0.1, 10, 0, 0.2] # opti\n",
    "# result = minimize(f, initial_guess, method='Powell') # solves well for melt rate offset\n",
    "# result = minimize(f, initial_guess, method='CG', options={'maxiter':2000}) % solves with precisison loss for full melt rate\n",
    "result = minimize(f, initial_guess, method='BFGS')\n",
    "\n",
    "print(result)\n",
    "\n",
    "m_ = melt_para(ftt[im_abs[0]], fts[im_abs[1]], toffs[im_abs[2]], uoffs[im_abs[3]])\n",
    "ii = np.argwhere(np.isnan(m_))\n",
    "print(np.max(m_))\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(' ')\n",
    "print(['GammaT *', str(ftt[2])])\n",
    "print(['GammaS *', str(fts[6])])\n",
    "print(['T offset ', str(toffs[3])])\n",
    "print(['ustar offset ', str(uoffs[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,1)\n",
    "fig.set_figwidth(10)\n",
    "ax[0].plot(num,spd)\n",
    "ax[1].plot(num,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relation of melt rates to ocean properties.\n",
    "At zero order, ice ablation increases with larger ambient ocean temperature and velocity as both factors enhance the fluxes across the ice-ocean boundary layer. From the conservation of heat and salt, a quadratic equation for the ablation rate can be found that generally yields a non-linear response to changes in ambient thermal driving T* and friction velocity u* = C_d^(1/2)*U_0, while a linearized expression is obtained under the assumption of small variations of the salinity in the boundary layer.\n",
    "\n",
    "If shear-driven turbulence from ambient currents was the primary source of mixing across the IOBL, the ablation rate would decrease to zero when the free-stream velocity U_0 vanishes. However, recent studies showed boundary layer turbulence is caused  by natural convection (buoyancy- or shear-driven) beneath a sloping ice face that leads to finite ablation rates in absence of ambient currents (find better wording here). These DNS simulations suggest \n",
    "\n",
    "while other processes have been proposed to . However, recent studies have shown that intrinsic instabilities in the convectively driven turbulence in \n",
    "\n",
    "\n",
    "Assessment of melt parameterizations.\n",
    "\n",
    "The observed melt rates can be parameterized. Several fits with different parameters. 3 eqn, 2 eqn, emprirical relationship.\n",
    "Varying strain would indicate a decreasing trend in melt rate that is not supported by the ocean observations. While the 3eqn. parameterization captures a large fraction of the variability, explanations for the offsets in u and t and the linear strain are less obvious. The 3 eqn fit suggests an offset in the observed velocities of 4 cm/s, which leads to an underestimate of the melt rates for low velocities. This may be related to buoyant plumes that are rising along the sloping ice base and dominate the velocity structure at the ice-ocean interface under low background flow conditions. If the linear trend in the strain is related the ice dynamics of the basal channel, this may also affect the slope and hence the plume velocity, providing an explanation for a trend in melt rates that woudl not be observed as changes in ocean properties 30-40 m below the ice base where our mooring is situated. The offset in temperature/ thermal driving is still hard to explain (needing a temperature inversion below the ice base), casting doubt on the absolute magnitude of the observed (parameterized) melting (and strain).\n",
    "\n",
    "Stanton numbers for:\n",
    "3eqn with melt offset, 3eqn with t&u offset, 2eqn same way; derive Cd range, gammat/gammas ratio; compare fit & distributions; project melt rates back with unceratainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('Spectral_r', 64)\n",
    "dt = t+2.15 # thermal driving\n",
    "bool = ~np.isnan(dt) & ~np.isnan(spd) & ~np.isnan(mm) # fint finite value tupels\n",
    "\n",
    "dtbins = np.arange(0, 0.35, 0.01)\n",
    "ubins = np.arange(-0.02, 0.2, 0.005)\n",
    "mbins  = np.arange(0, 4, 0.05)\n",
    "utbins  = np.arange(-0.001, 0.04, 0.0005)\n",
    "\n",
    "hist = stats.binned_statistic_2d( spd[bool], dt[bool], None, bins=[ubins, dtbins], statistic='count')  # Returns a object\n",
    "hist.statistic[hist.statistic == 0] = np.nan  # Sets all values of 0 to nan as log10(0) = -inf\n",
    "\n",
    "#In using stats.binned_statistic_2d, the input argument needs to be a 1-D array.  If you're using higher-\n",
    "#dimensional data, such as model data, then you would want to flatten the input arrays with np.ravel(). \n",
    "#Similarly the input arguments should contain no NaNs.  If they do, you would want to remove then with\n",
    "#bool = ~np.isnan(x) & ~np.isnan(y)\n",
    "#hist = stats.binned_statistic_2d(x[bool], y[bool], None, bins=[xbins,ybins], statistic='mean').statistic  \n",
    "\n",
    "mmean = stats.binned_statistic_2d( spd[bool], dt[bool], mm[bool], bins=[ubins, dtbins], statistic='mean')  # Returns a object\n",
    "\n",
    "# melt rate space\n",
    "muhist = stats.binned_statistic_2d( spd[bool], mm[bool], None, bins=[ubins, mbins], statistic='count')  # Returns a object\n",
    "muhist.statistic[muhist.statistic == 0] = np.nan  # Sets all values of 0 to nan as log10(0) = -inf\n",
    "mumean = stats.binned_statistic_2d( spd[bool], mm[bool], dt[bool], bins=[ubins, mbins], statistic='mean')  # Returns a object\n",
    "\n",
    "\n",
    "mthist = stats.binned_statistic_2d( dt[bool], mm[bool], None, bins=[dtbins, mbins], statistic='count')  # Returns a object\n",
    "mthist.statistic[mthist.statistic == 0] = np.nan  # Sets all values of 0 to nan as log10(0) = -inf\n",
    "mtmean = stats.binned_statistic_2d( dt[bool], mm[bool], spd[bool], bins=[dtbins, mbins], statistic='mean')  # Returns a object\n",
    "\n",
    "# u*t space\n",
    "\n",
    "uthist = stats.binned_statistic_2d( dt[bool]*spd[bool], mm[bool], None, bins=[utbins, mbins], statistic='count')  # Returns a object\n",
    "uthist.statistic[uthist.statistic == 0] = np.nan  # Sets all values of 0 to nan as log10(0) = -inf\n",
    "uttmean = stats.binned_statistic_2d( dt[bool]*spd[bool], mm[bool], dt[bool], bins=[utbins, mbins], statistic='mean')  # Returns a object\n",
    "\n",
    "#################### plotting\n",
    "\n",
    "fig, ax = plt.subplots(1, 2,figsize=np.array([18, 10]))\n",
    "\n",
    "plt.sca(ax[0]) \n",
    "image = plt.pcolormesh(ubins, dtbins, np.log10(hist.statistic.T), cmap=cmap, shading='flat') \n",
    "plt.title('Distribution of u-dt pairs')\n",
    "\n",
    "plt.sca(ax[1]) \n",
    "image = plt.pcolormesh(ubins, dtbins, mmean.statistic.T, cmap=cmap, shading='flat') \n",
    "plt.title('Mean melt rate')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.025)\n",
    "fig.colorbar(image, ax=ax[0], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='Log10 Number of Data Points'); \n",
    "fig.colorbar(image, ax=ax[1], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='melt rate [m/yr]');\n",
    "\n",
    "# metl distribution plots\n",
    "fig, ax = plt.subplots(1, 2,figsize=np.array([18, 10]))\n",
    "\n",
    "plt.sca(ax[0]) \n",
    "image = plt.pcolormesh(mbins, ubins, np.log10(muhist.statistic), cmap=cmap, shading='flat') \n",
    "plt.title('Distribution of u-melt pairs')\n",
    "\n",
    "plt.sca(ax[1]) \n",
    "image = plt.pcolormesh(mbins, dtbins, np.log10(mthist.statistic), cmap=cmap, shading='flat') \n",
    "plt.title('Distribution of dT-melt pairs')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.025)\n",
    "fig.colorbar(image, ax=ax[0], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='Log10 Number of Data Points'); \n",
    "fig.colorbar(image, ax=ax[1], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='Log10 Number of Data Points');\n",
    "\n",
    "# melt mean plots\n",
    "fig, ax = plt.subplots(1, 2,figsize=np.array([18, 10]))\n",
    "\n",
    "plt.sca(ax[0]) \n",
    "image = plt.pcolormesh(mbins, ubins, mumean.statistic, cmap=cmap, shading='flat') \n",
    "plt.title('mean dT on distribution of u-melt pairs')\n",
    "\n",
    "plt.sca(ax[1]) \n",
    "image = plt.pcolormesh(mbins, dtbins, mtmean.statistic, cmap=cmap, shading='flat') \n",
    "plt.title('mean speed on distribution of dT-melt pairs')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.025)\n",
    "fig.colorbar(image, ax=ax[0], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='dT [degC]'); \n",
    "fig.colorbar(image, ax=ax[1], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='spd [m/s]');\n",
    "\n",
    "# ut-melt plots\n",
    "fig, ax = plt.subplots(1, 2,figsize=np.array([18, 10]))\n",
    "\n",
    "plt.sca(ax[0]) \n",
    "image = plt.pcolormesh(utbins, mbins, np.log10(uthist.statistic.T), cmap=cmap, shading='flat') \n",
    "plt.title('Distribution of uT-melt pairs')\n",
    "\n",
    "plt.sca(ax[1]) \n",
    "image = plt.pcolormesh(utbins, mbins, uttmean.statistic.T, cmap=cmap, shading='flat') \n",
    "plt.title('mean temperature on distribution of uT-melt pairs')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.025)\n",
    "fig.colorbar(image, ax=ax[0], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='Log10 Number of Data Points'); \n",
    "fig.colorbar(image, ax=ax[1], orientation='horizontal', shrink=0.8, aspect=30, pad=0.08, label='dT [degC]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = map_setup(figsize,projection) \n",
    "\n",
    "ubar = stats.binned_statistic_2d(lat, lon, u, bins=[latbins, lonbins], statistic='mean')  \n",
    "vbar = stats.binned_statistic_2d(lat, lon, v, bins=[latbins, lonbins], statistic='mean')  \n",
    "meanflow = np.sqrt(ubar.statistic ** 2 + vbar.statistic ** 2)\n",
    "\n",
    "image = plt.pcolormesh(lonbins, latbins, meanflow, cmap=cmap, shading='flat',transform=ccrs.PlateCarree()) \n",
    "plt.title('Speed of Mean Surface Currents')\n",
    "plt.clim(0, 80) \n",
    "\n",
    "fig.colorbar(image, ax=ax, orientation='vertical', shrink=0.5, aspect=30, pad=0.05, label='Speed (cm/s)'); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fio_fieldwork] *",
   "language": "python",
   "name": "conda-env-fio_fieldwork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
